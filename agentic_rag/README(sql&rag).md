SQL + RAG Query Engine

Project Overview
This project is an AI-driven Hybrid Query Engine that can process both SQL-based structured queries and unstructured document searches using LlamaIndex, Ollama (Mistral), and Qdrant.
Features
âœ… Structured Data: Uses SQL to query city statistics like population & state.
âœ… Unstructured Data: Retrieves answers from Wikipedia PDFs using embeddings.
âœ… Smart Query Routing: Uses LLMs to decide whether to use SQL or vector search.

 Tech Stack
LlamaIndex: For vector-based document search (RAG).
Ollama (Mistral LLM): For intelligent query understanding.
Qdrant: For efficient vector storage & retrieval.
SQLAlchemy: For managing structured SQL databases.
HuggingFace Embeddings: To encode text into vector representations.

Installation Guide
1ï¸âƒ£ Clone the Repository
Fork and clone the repo:
git clone https://github.com/sakshiware_25/ai-engineering-hub.git
 cd ai-engineering-hub

2ï¸âƒ£ Install Dependencies
Ensure you have Python 3.8+ installed, then run:
pip install -r requirements.txt

3ï¸âƒ£ Download Model & PDFs
Place your HuggingFace embeddings model at the specified path.
Add Wikipedia PDFs inside the /data/ folder.

ğŸš€ How to Run the Code
Run the following command to start the query engine:
python llamacloud_sql_router.py


ğŸ“Š Example Queries
Once running, try:
Which city has the highest population?
Where is the Space Needle located?
How do people in Chicago get around?

The system will intelligently route the query between SQL & RAG!


ğŸ“© Contact
For any questions, feel free to open an issue or reach out! ğŸš€
